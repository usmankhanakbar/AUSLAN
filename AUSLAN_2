{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14447230,"sourceType":"datasetVersion","datasetId":9228384}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import roc_curve, auc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-10T04:39:45.145241Z","iopub.execute_input":"2026-01-10T04:39:45.145457Z","iopub.status.idle":"2026-01-10T04:40:00.736295Z","shell.execute_reply.started":"2026-01-10T04:39:45.145433Z","shell.execute_reply":"2026-01-10T04:40:00.735702Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_landmarks(DATA_DIR):\n    classes = [\n        d for d in os.listdir(DATA_DIR)\n        if os.path.isdir(os.path.join(DATA_DIR, d))\n    ]\n    num_classes = len(classes)\n\n    for label in classes:\n        label_path = os.path.join(DATA_DIR, label)\n\n        for subject in os.listdir(label_path):\n            subject_path = os.path.join(label_path, subject)\n            if not os.path.isdir(subject_path):\n                continue\n\n            for file in os.listdir(subject_path):\n                if not file.endswith(\".npy\"):\n                    continue\n\n                file_path = os.path.join(subject_path, file)\n\n                try:\n                    data = np.load(file_path)\n                except FileNotFoundError:\n                    print(\"⚠️ Missing:\", file_path)\n                    continue\n\n                yield data, label, num_classes\n\n\ndef segregate_dataset(dataset,length_dataset):\n\n    dataset = dataset.shuffle(\n        buffer_size = length_dataset,\n        seed = 42,\n        reshuffle_each_iteration = False\n    )\n    train_size = int(0.7 * length_dataset)\n    val_size = int(0.15 * length_dataset)\n    test_size = length_dataset - train_size - val_size\n\n    train_ds = dataset.take(train_size)\n    remaining = dataset.skip(train_size)\n\n    val_ds = remaining.take(val_size)\n    test_ds = remaining.skip(val_size)\n\n    yield train_ds, val_ds, test_ds\n\ndef get_shape_ds(dataset):\n    for data, label in dataset.take(1):\n        print(f'Data shape: {data.shape}')\n        print(f'Label shape: {label.shape}')\n# Here I define the transformer Encoder\nclass TransformerEncoder(tf.keras.layers.Layer):\n    def __init__(self, embed_dim, num_heads, mlp_dim, dropout=0.1):\n        super().__init__()\n        self.norm1 = tf.keras.layers.LayerNormalization()\n        self.attn = tf.keras.layers.MultiHeadAttention(\n            num_heads=num_heads,\n            key_dim=embed_dim,\n            output_shape=embed_dim\n        )\n        self.dropout1 = tf.keras.layers.Dropout(dropout)\n\n        self.norm2 = tf.keras.layers.LayerNormalization()\n        self.mlp = tf.keras.Sequential([\n            tf.keras.layers.Dense(mlp_dim, activation=\"gelu\"),\n            tf.keras.layers.Dropout(dropout),\n            tf.keras.layers.Dense(embed_dim),\n            tf.keras.layers.Dropout(dropout),\n        ])\n\n    def call(self, x, training=False, return_attention=False):\n        attn_output, attn_scores = self.attn(\n            self.norm1(x),\n            self.norm1(x),\n            return_attention_scores=True\n        )\n\n        x = x + self.dropout1(attn_output, training=training)\n        x = x + self.mlp(self.norm2(x), training=training)\n\n        if return_attention:\n            return x, attn_scores\n        return x\n# Extract Attention Scores\ndef build_attention_extractor(vit_model, layer_index=0):\n    return tf.keras.Model(\n        inputs=vit_model.input,\n        outputs=vit_model.layers[layer_index].output\n    )\n\n# Visualize Attention Maps\ndef visualize_attention(model, dataset, sample_id=0):\n    for x, y in dataset.take(1):\n        sample = x[sample_id:sample_id+1]\n\n    attention_model = tf.keras.Model(\n        inputs=model.input,\n        outputs=model.layers[-3].output  # Transformer layer\n    )\n\n    attn_scores = attention_model(sample, training=False)\n    attn_scores = attn_scores.numpy().mean(axis=1)  # avg heads\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(attn_scores[0], cmap=\"viridis\")\n    plt.colorbar()\n    plt.title(\"Transformer Attention Map\")\n    plt.xlabel(\"Landmark Tokens\")\n    plt.ylabel(\"Landmark Tokens\")\n    plt.show()\nclass expand_dim(tf.keras.layers.Layer):\n    def __init__(self, axis):\n        super(expand_dim, self).__init__()\n        self.axis = axis\n\n    def call(self, inputs):\n        return tf.expand_dims(inputs, axis=self.axis)\n\n# Here I define the ViT\ndef build_vit(\n    input_dim,\n    num_classes,\n    num_tokens=1662,     # landmark count\n    embed_dim=128,\n    num_heads=4,\n    mlp_dim=64,\n    num_layers=6,\n    dropout=0.1\n):\n    inputs = tf.keras.Input(shape=(input_dim,))\n\n    # Convert landmark vector → tokens\n    x = tf.keras.layers.Reshape((num_tokens, 1))(inputs)\n    x = tf.keras.layers.Dense(embed_dim)(x)\n\n    # Positional Embedding\n    positions = tf.range(start=0, limit=num_tokens, delta=1)\n    pos_embed = tf.keras.layers.Embedding(\n        input_dim=num_tokens,\n        output_dim=embed_dim\n    )(positions)\n\n    x = x + pos_embed\n\n    # Transformer Encoder Stack\n    for _ in range(num_layers):\n        x = TransformerEncoder(\n            embed_dim, num_heads, mlp_dim, dropout\n        )(x)\n\n    # Classification Head\n    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n    x = tf.keras.layers.LayerNormalization()(x)\n    outputs = tf.keras.layers.Dense(\n        num_classes,\n        activation=\"softmax\"\n    )(x)\n    exp_dim = expand_dim(axis=1)\n    outputs = exp_dim(outputs)\n\n    model = tf.keras.Model(inputs, outputs)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T04:40:46.722835Z","iopub.execute_input":"2026-01-10T04:40:46.723137Z","iopub.status.idle":"2026-01-10T04:40:46.739770Z","shell.execute_reply.started":"2026-01-10T04:40:46.723113Z","shell.execute_reply":"2026-01-10T04:40:46.738984Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == '__main__':\n    DATA_DIR = '/kaggle/input/auslan/AUSLAN_Data'\n    results = get_landmarks(DATA_DIR)\n    print(results)\n    composite_features, alphabet, num_classes = zip(*results)\n    composite_features = np.array(composite_features)\n    alphabet = np.array(alphabet)\n    num_classes = np.max(num_classes)\n    # lets generate a tensorflow dataset\n    dataset = tf.data.Dataset.from_tensor_slices((composite_features, alphabet\n                                                  ))\n    # Ok now we have the dataset so now we can segregate it into\n    # Training, validation and test datasets\n    # Lets do that\n    # But we do so by declaring a function\n    # But First we need to convert the label i-e alphabet into one hot encoding\n    label_lookup = tf.keras.layers.StringLookup(output_mode = \"int\")\n    label_lookup.adapt(alphabet)\n    #num_classes = label_lookup.vocabulary_size()\n    one_hot_encoder = tf.keras.layers.CategoryEncoding(\n        num_tokens = num_classes,\n        output_mode = \"one_hot\"\n    )\n    dataset = dataset.map(\n        lambda x,y: (x, one_hot_encoder(label_lookup(y)-1)),\n        num_parallel_calls = tf.data.AUTOTUNE\n    )\n    segregated_dataset = segregate_dataset(dataset, len(composite_features))\n    train_ds, val_ds, test_ds = next(segregated_dataset)\n\n    # Now we convert the datasets into batches\n    BATCH_SIZE = 32\n    train_ds = train_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n    val_ds = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n    test_ds = test_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n    # Lets check the shape of the datasets\n    # get_shape_ds(train_ds)\n    # get_shape_ds(val_ds)\n    # get_shape_ds(test_ds)\n    INPUT_DIM = composite_features.shape[1]\n    NUM_CLASSES = num_classes\n    # Lets Build the ViT Model\n    vit_model = build_vit(\n        input_dim=INPUT_DIM,\n        num_classes=NUM_CLASSES\n    )\n    # Here we compile our ViT Model\n    vit_model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n    vit_model.summary()\n    # Now we define the Model Checkpoint Callback\n    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n    filepath=\"vit_best_model.keras\",\n    monitor=\"val_accuracy\",\n    save_best_only=True,\n    save_weights_only=False,\n    verbose=1\n    )\n    # Defining our CSV logger\n    csv_logger_cb = tf.keras.callbacks.CSVLogger(\n    filename=\"/kaggle/working/vit_training_log.csv\",\n    append=True\n    )\n    # Defining Early Stopping Callback\n    early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\",\n    patience=10,\n    restore_best_weights=True\n    )\n    callbacks = [\n    checkpoint_cb,\n    csv_logger_cb,\n    early_stopping_cb\n    ]\n    # Now training the Model\n    print(\"Training of the model starts here...\")\n    history = vit_model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=100,\n    callbacks=callbacks\n    )\n    test_loss, test_acc = vit_model.evaluate(test_ds)\n    print(f\"Test Accuracy: {test_acc:.4f}\")\n\n    y_true = []\n    y_pred = []\n\n    for x, y in test_ds:\n        preds = vit_model.predict(x)\n        y_true.extend(np.argmax(y.numpy(), axis=1))\n        y_pred.extend(np.argmax(preds, axis=1))\n\n\n    cm = confusion_matrix(y_true, y_pred)\n\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(\n        cm,\n        annot=True,\n        fmt=\"d\",\n        cmap=\"Blues\"\n    )\n    plt.xlabel(\"Predicted Label\")\n    plt.ylabel(\"True Label\")\n    plt.title(\"Confusion Matrix for AUSLAN Classification\")\n    plt.savefig(\"/kaggle/working//Confusion.png\")\n    plt.show()\n\n    print(classification_report(\n    y_true,\n    y_pred,\n    digits=4))\n\n    precision, recall, f1, support = precision_recall_fscore_support(\n    y_true,\n    y_pred,\n    average=\"macro\"\n    )\n\n    print(f\"Macro Precision: {precision:.4f}\")\n    print(f\"Macro Recall: {recall:.4f}\")\n    print(f\"Macro F1-score: {f1:.4f}\")\n\n    plt.figure(figsize=(12, 5))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n    plt.plot(history.history[\"val_accuracy\"], label=\"Val Accuracy\")\n    plt.legend()\n    plt.title(\"Accuracy Curve\")\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n    plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n    plt.legend()\n    plt.title(\"Loss Curve\")\n    plt.savefig(\"/kaggle/working//LossCurve.png\")\n    plt.show()\n\n\n    ## ROC AUC Curve\n    y_true_bin = label_binarize(y_true, classes=range(NUM_CLASSES))\n    y_pred_prob = np.array([\n    vit_model.predict(x) for x, _ in test_ds\n    ]).reshape(len(y_true), NUM_CLASSES)\n\n    for i in range(NUM_CLASSES):\n        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_prob[:, i])\n        roc_auc = auc(fpr, tpr)\n        plt.plot(fpr, tpr, label=f\"Class {i} (AUC={roc_auc:.2f})\")\n\n    plt.legend()\n    plt.title(\"ROC Curves\")\n    plt.savefig(\"/kaggle/working//RoC.png\")\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T04:40:54.690224Z","iopub.execute_input":"2026-01-10T04:40:54.690986Z","execution_failed":"2026-01-10T04:41:28.129Z"}},"outputs":[],"execution_count":null}]}